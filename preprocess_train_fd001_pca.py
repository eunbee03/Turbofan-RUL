# preprocess_train_fd001_pca.py

import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

# 1. íŒŒì¼ ê²½ë¡œ
input_path = "data/train_FD001.txt"
output_path = "data/rul_fd001_pca_filtered.csv"

# 2. ì»¬ëŸ¼ ì´ë¦„ ì§€ì • (C-MAPSS FD001 ê¸°ì¤€: 3 + 21 = 24 ì—´)
column_names = ['unit', 'cycle'] + [f'op_setting_{i}' for i in range(1, 4)] + [f's{i}' for i in range(1, 22)]

# 3. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_csv(input_path, sep=r"\s+", header=None, names=column_names)

# 4. ì„¼ì„œ ì»¬ëŸ¼ ì¶”ì¶œ
sensor_cols = [col for col in df.columns if col.startswith('s')]
print("ğŸ“Œ ì„¼ì„œ ì»¬ëŸ¼ ìˆ˜:", len(sensor_cols))

# 5. í‘œì¤€í™”
X_scaled = StandardScaler().fit_transform(df[sensor_cols])

# 6. PCA (ë¶„ì‚° 90% ìœ ì§€)
pca = PCA(n_components=0.9)
X_pca = pca.fit_transform(X_scaled)

# 7. ì¤‘ìš” ì„¼ì„œ ì¶”ì¶œ
loadings = pd.DataFrame(pca.components_.T, index=sensor_cols)
sensor_scores = loadings.abs().sum(axis=1)
top_sensors = sensor_scores.sort_values(ascending=False).head(10).index.tolist()
print("âœ… PCAë¡œ ì„ ì •ëœ ì¤‘ìš” ì„¼ì„œ:", top_sensors)

# 8. í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì €ì¥
df_filtered = df[['unit', 'cycle'] + top_sensors]
df_filtered.to_csv(output_path, index=False)
print(f"ğŸ“ ì €ì¥ ì™„ë£Œ: {output_path}")
